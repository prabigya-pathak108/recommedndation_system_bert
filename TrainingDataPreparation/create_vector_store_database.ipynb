{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import json\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabigya\\AppData\\Local\\Temp\\ipykernel_5184\\4135301190.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "DATASET_FILE =r\"C:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommedation_algo_system\\fine_tuning\\dataset\\flipkart_com-ecommerce_sample.csv\"\n",
    "df = pd.read_csv(DATASET_FILE)\n",
    "df = df.drop_duplicates(subset = [\"pid\"])\n",
    "df = df[['product_name','product_category_tree','description','brand','discounted_price','product_specifications',\"overall_rating\"]]\n",
    "df2 = df['product_name']\n",
    "df = df.astype(str)\n",
    "df = df.dropna()\n",
    "df = df.applymap(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabigya\\AppData\\Local\\Temp\\ipykernel_5184\\3197736538.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_rdf[\"description\"]=filtered_rdf[\"description\"]+\" Its rating is \"+filtered_rdf[\"overall_rating\"]+\".\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "# Function to extract keys and values from product_specifications column\n",
    "def extract_specifications(specifications):\n",
    "    pairs = re.findall(r'\"key\"=>\"(.*?)\", \"value\"=>\"(.*?)\"', specifications)\n",
    "    pairs_formatted = [f\"Feature  {key}:{value}.\" for key, value in pairs]\n",
    "    return ' '.join(pairs_formatted)\n",
    "\n",
    "def apply_remove_gret_sign(text):\n",
    "    text=str(text).replace(\"[\",\"\").replace(\"]\",\"\").replace(\">>\",\",\").replace(\" ,\",\",\")\n",
    "    return text\n",
    "def capitalize_each_letter_text(text):\n",
    "    text=str(text).title()\n",
    "    return text\n",
    "\n",
    "df['product_specifications'] = df['product_specifications'].apply(extract_specifications)\n",
    "df[\"product_category_tree\"]=df[\"product_category_tree\"].apply(apply_remove_gret_sign)\n",
    "df[\"product_name\"]=df[\"product_name\"].apply(capitalize_each_letter_text)\n",
    "\n",
    "df_no_rating = df[df[\"overall_rating\"] == \"no rating available\"]\n",
    "df_with_rating = df[df[\"overall_rating\"] != \"no rating available\"]\n",
    "sampled_no_rating = df_no_rating.sample(n=len(df_with_rating) // 10, random_state=1)\n",
    "\n",
    "# Combine the two DataFrames\n",
    "rdf = pd.concat([df_with_rating, sampled_no_rating]).sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "filtered_rdf = rdf[\n",
    "    (rdf['product_category_tree'].notnull()) & (rdf['description'].notnull()) &\n",
    "    (rdf['product_category_tree'].str.len() > 25) & (rdf['description'].str.len() > 25)\n",
    "]\n",
    "filtered_rdf[\"description\"]=filtered_rdf[\"description\"]+\" Its rating is \"+filtered_rdf[\"overall_rating\"]+\".\"\n",
    "necessary_cols=filtered_rdf\n",
    "necessary_cols.to_csv(r\"C:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommendation_system_ecommerce\\dataset\\usable_data.csv\",index=False)\n",
    "necessary_data_dict = necessary_cols.to_dict(orient='index')\n",
    "\n",
    "\n",
    "output_file_path = r'C:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommendation_system_ecommerce\\dataset\\vector_storing_documents.json'\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(necessary_data_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommend_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommend_venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pydantic import BaseModel, ConfigDict, Field, SecretStr\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "class FineTunedHuggingFaceModel(Embeddings):\n",
    "    def __init__(self, model_name: str):\n",
    "        \"\"\"Initialize with the model name or path.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name, device=\"cpu\")\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        # Get the embeddings for the documents\n",
    "        embeddings = self.model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "        # Convert the tensor embeddings into a list of lists (each inner list represents an embedding)\n",
    "        return embeddings.cpu().numpy().tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=r\"C:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\bge_models_weights\"\n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    model_dir, device=\"cpu\")\n",
    "embeddings=FineTunedHuggingFaceModel(model_name=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding dimension: {len(embeddings.embed_query('example query'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_vector_store(input_file_folder_loc,output_file_folder_loc,embedding_model):\n",
    "    os.makedirs(output_file_folder_loc, exist_ok=True)\n",
    "    files_in_output_folder=os.listdir(output_file_folder_loc)\n",
    "    if len(files_in_output_folder)>0:\n",
    "        return \n",
    "    document_created_list=[]\n",
    "    for file_name in os.listdir(input_file_folder_loc):\n",
    "        input_file_path = os.path.join(input_file_folder_loc, file_name)\n",
    "\n",
    "        if os.path.isfile(input_file_path) and file_name.lower().endswith(\".json\"):\n",
    "            try:\n",
    "                loaded_data=json.load(open(input_file_path))\n",
    "\n",
    "                for key,value in loaded_data.items():\n",
    "                    necessary_data = {}\n",
    "                    try:\n",
    "                        \n",
    "                        necessary_data[\"product_name\"]=value[\"product_name\"]\n",
    "                        necessary_data[\"overall_rating\"]=value[\"overall_rating\"]\n",
    "                        necessary_data[\"product_category_tree\"]=value[\"product_category_tree\"]\n",
    "                        necessary_data[\"brand\"]=value[\"brand\"]\n",
    "                        product_specification=value[\"product_specifications\"]\n",
    "                        document = Document(\n",
    "                            page_content=product_specification,\n",
    "                            metadata=necessary_data\n",
    "                        )\n",
    "                        document_created_list.append(document)\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "    \n",
    "    vector_store = FAISS.from_documents(document_created_list, embedding_model)\n",
    "    vector_store.save_local(output_file_folder_loc)\n",
    "\n",
    "\n",
    "training_data_path=r\"C:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommendation_system_ecommerce\\dataset\"\n",
    "output_vector_loc=r'C:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommendation_system_ecommerce\\dataset\\vector_store'\n",
    "create_vector_store(training_data_path,output_vector_loc,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vector_loc=r'C:\\Users\\prabigya\\Desktop\\work_here\\Recommendo-Personalized-Shopping-Powered-by-LLMs\\recommendation_system_ecommerce\\dataset\\vector_store'\n",
    "loaded_vector_store = FAISS.load_local(output_vector_loc, embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Feature  in the box:mobile holder. Feature  brand:bracketron. Feature  model:tour window hip kicker. Feature  color:black.\n",
      "Metadata: {'product_name': 'Bracketron Tour Window Hip Kicker', 'overall_rating': '4', 'product_category_tree': '\"automotive, accessories & spare parts, car electronics & accessories, car mobile accessories, car mobile holders\"', 'brand': 'bracketron'}\n",
      "Dissimilarity score: 0.8901824951171875\n",
      "\n",
      " --------------------------------------------------\n",
      "Content: Feature  in the box:mobile holder with adjustable tool. Feature  brand:fly. Feature  model:mini clip mobile holder. Feature  color:black.\n",
      "Metadata: {'product_name': 'Fly Mini Clip Mobile Holder', 'overall_rating': '3.6', 'product_category_tree': '\"automotive, accessories & spare parts, car electronics & accessories, car mobile accessories, car mobile holders\"', 'brand': 'fly'}\n",
      "Dissimilarity score: 0.9018765687942505\n",
      "\n",
      " --------------------------------------------------\n",
      "Content: Feature  connectors:micro. Feature  brand:mobiware. Feature  model number:mw4p. Feature  battery capacity:4000 mah. Feature  model name:mobiware 4000 mah pocket powerbank. Feature  battery type:lithium-ion. Feature  power source:ac adpter. Feature  color:white-pink. Feature  covered in warranty:3 month replacement for manufacturer defects. Feature  warranty summary:3 month. Feature  warranty service type:service center. Feature  not covered in warranty:external damage not covered in warranty. Feature  sales package:one powerbank , one cable.\n",
      "Metadata: {'product_name': 'Mobiware Mw4P Mobiware 4000 Mah Pocket Powerbank 4000 Mah', 'overall_rating': '5', 'product_category_tree': '\"mobiles & accessories, mobile accessories, power banks, mobiware power banks, mobiware mw4p mobiware 4000 mah pocket powerbank...\"', 'brand': 'mobiware'}\n",
      "Dissimilarity score: 0.9057236909866333\n",
      "\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "query = \"mobile\"\n",
    "results = loaded_vector_store.similarity_search_with_score(query,k=4)\n",
    "\n",
    "# Check similarity scores and proceed if greater than threshold\n",
    "for result, score in results:\n",
    "    if len(str(result.page_content))>20:\n",
    "        print(f\"Content: {result.page_content}\")\n",
    "        print(f\"Metadata: {result.metadata}\")\n",
    "        print(f\"Dissimilarity score: {score}\")\n",
    "        print(\"\\n\",\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommend_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
